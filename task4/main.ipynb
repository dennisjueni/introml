{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- target size in load_img [224, 224]\n",
    "- different pooling\n",
    "- include_top = True\n",
    "- PCA size versuchen\n",
    "- standardscaler nochmals versuchen\n",
    "- different order of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def get_vector(image_path, model):\n",
    "        img = image.load_img(image_path, target_size=(224, 224))\n",
    "        input_arr = image.img_to_array(img)\n",
    "        input_arr = np.array([input_arr])\n",
    "        return model.predict(input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_img = sorted(glob.glob('data' + '/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [14:33<00:00, 11.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.efficientnet import EfficientNetB1\n",
    "\n",
    "e1_model = EfficientNetB1(weights='imagenet', include_top=False, pooling='avg')\n",
    "e1_feature_list = [get_vector(item, e1_model) for item in tqdm(sorted_img)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "size = 20\n",
    "pca = PCA(n_components=size, random_state=2)\n",
    "\n",
    "e1_fla = [item.flatten() for item in e1_feature_list]\n",
    "li_1 = pca.fit_transform(np.array(e1_fla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59515it [00:00, 162023.23it/s]\n"
     ]
    }
   ],
   "source": [
    "file = open('train_triplets.txt')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for line in tqdm(file):\n",
    "    \n",
    "    words = line.split()\n",
    "    \n",
    "    index_x = int(words[0])\n",
    "    index_y1 = int(words[1])\n",
    "    index_y2 = int(words[2])\n",
    "    \n",
    "    x = li_1[index_x]\n",
    "    y1 = li_1[index_y1]\n",
    "    y2 = li_1[index_y2]\n",
    "    \n",
    "    \n",
    "    if counter % 2 == 0:\n",
    "        temp_list.append(np.concatenate((x, y1, y2), axis=None).reshape(3*size))\n",
    "    else:\n",
    "        temp_list.append(np.concatenate((x, y2, y1), axis=None).reshape(3*size))\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "X = pd.DataFrame(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(np.resize([1,0], 59515))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7106854838709677\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(early_stopping=True, random_state=69, tol= 1e-5)\n",
    "clf.fit(X_train, np.ravel(y_train))\n",
    "score = clf.score(X_test, np.ravel(y_test))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8:\n",
    "    0.704133064516129\n",
    "    0.68331594359\n",
    "18:\n",
    "    0.7259744623655914\n",
    "    0.698327218875\n",
    "19:\n",
    "    0.7326948924731183\n",
    "    0.697182861566\n",
    "20:\n",
    "    0.7296706989247311\n",
    "    0.69937060348\n",
    "21:\n",
    "    0.7281586021505376\n",
    "    0.68876846959\n",
    "22:\n",
    "    0.7328629032258065\n",
    "    0.685705630911\n",
    "32:\n",
    "    0.7286626344086021\n",
    "    \n",
    "64:\n",
    "    0.735383064516129\n",
    "    \n",
    "512:\n",
    "    0.8146841397849462\n",
    "    0.664501363132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59544it [00:00, 178687.38it/s]\n"
     ]
    }
   ],
   "source": [
    "testFile = open('test_triplets.txt')\n",
    "\n",
    "test_X = pd.DataFrame()\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "for line in tqdm(testFile):\n",
    "    \n",
    "    words = line.split()\n",
    "    \n",
    "    index_x = int(words[0])\n",
    "    index_y1 = int(words[1])\n",
    "    index_y2 = int(words[2])\n",
    "    \n",
    "    x = li_1[index_x]\n",
    "    y1 = li_1[index_y1]\n",
    "    y2 = li_1[index_y2]\n",
    "    \n",
    "    temp_list.append(np.concatenate((x, y1, y2), axis=None).reshape(3*size))\n",
    "\n",
    "test_X = pd.DataFrame(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.60394118\n",
      "Validation score: 0.701109\n",
      "Iteration 2, loss = 0.57315946\n",
      "Validation score: 0.704133\n",
      "Iteration 3, loss = 0.56861236\n",
      "Validation score: 0.712534\n",
      "Iteration 4, loss = 0.56618962\n",
      "Validation score: 0.715894\n",
      "Iteration 5, loss = 0.56331421\n",
      "Validation score: 0.713206\n",
      "Iteration 6, loss = 0.56165920\n",
      "Validation score: 0.710349\n",
      "Iteration 7, loss = 0.56070021\n",
      "Validation score: 0.717574\n",
      "Iteration 8, loss = 0.55970611\n",
      "Validation score: 0.714046\n",
      "Iteration 9, loss = 0.55917075\n",
      "Validation score: 0.717070\n",
      "Iteration 10, loss = 0.55757478\n",
      "Validation score: 0.710013\n",
      "Iteration 11, loss = 0.55708000\n",
      "Validation score: 0.716734\n",
      "Iteration 12, loss = 0.55613754\n",
      "Validation score: 0.720766\n",
      "Iteration 13, loss = 0.55593201\n",
      "Validation score: 0.719590\n",
      "Iteration 14, loss = 0.55475685\n",
      "Validation score: 0.719254\n",
      "Iteration 15, loss = 0.55585385\n",
      "Validation score: 0.716398\n",
      "Iteration 16, loss = 0.55505180\n",
      "Validation score: 0.726815\n",
      "Iteration 17, loss = 0.55433891\n",
      "Validation score: 0.709509\n",
      "Iteration 18, loss = 0.55455347\n",
      "Validation score: 0.717742\n",
      "Iteration 19, loss = 0.55311191\n",
      "Validation score: 0.720430\n",
      "Iteration 20, loss = 0.55331234\n",
      "Validation score: 0.723454\n",
      "Iteration 21, loss = 0.55257017\n",
      "Validation score: 0.709845\n",
      "Iteration 22, loss = 0.55273538\n",
      "Validation score: 0.725134\n",
      "Iteration 23, loss = 0.55249120\n",
      "Validation score: 0.725974\n",
      "Iteration 24, loss = 0.55186353\n",
      "Validation score: 0.718918\n",
      "Iteration 25, loss = 0.55243491\n",
      "Validation score: 0.719422\n",
      "Iteration 26, loss = 0.55236570\n",
      "Validation score: 0.721270\n",
      "Iteration 27, loss = 0.55257261\n",
      "Validation score: 0.723118\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(early_stopping=True, random_state=69, verbose=True, tol= 1e-5, alpha=0.1, beta).fit(X, np.ravel(y))\n",
    "test_y = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27253\n"
     ]
    }
   ],
   "source": [
    "print(sum(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('answer.txt', test_y, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
